{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the dataset\n",
    "dataset = pd.read_csv(r\"F:\\Andrina\\Externship\\Code Files\\bank.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>deposit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>2343</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>1042</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>45</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>1467</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     job  marital  education default  balance housing loan  contact  \\\n",
       "0   59  admin.  married  secondary      no     2343     yes   no  unknown   \n",
       "1   56  admin.  married  secondary      no       45      no   no  unknown   \n",
       "\n",
       "   day month  duration  campaign  pdays  previous poutcome deposit  \n",
       "0    5   may      1042         1     -1         0  unknown     yes  \n",
       "1    5   may      1467         1     -1         0  unknown     yes  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age          False\n",
       "job          False\n",
       "marital      False\n",
       "education    False\n",
       "default      False\n",
       "balance      False\n",
       "housing      False\n",
       "loan         False\n",
       "contact      False\n",
       "day          False\n",
       "month        False\n",
       "duration     False\n",
       "campaign     False\n",
       "pdays        False\n",
       "previous     False\n",
       "poutcome     False\n",
       "deposit      False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking for null values\n",
    "dataset.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the columns day, month and pdays do not affect the final output, thus removing those columns from x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data to  x and y \n",
    "#the columns day, month and pdays do not affect the final output, thus removing those columns from x \n",
    "m = dataset.iloc[:,0:9]\n",
    "n = dataset.iloc[:,11:13]\n",
    "o = dataset.iloc[:,14:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = m.join(n)\n",
    "x = x.join(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.values\n",
    "#y is the output data. It consists of the deposit column\n",
    "y = dataset.iloc[:,16:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([59, 'admin.', 'married', 'secondary', 'no', 2343, 'yes', 'no',\n",
       "       'unknown', 1042, 1, 0, 'unknown'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]\n",
    "# the current index values of the coulmns in x are as below\n",
    "#  0- age\n",
    "#  1- job\n",
    "#  2- marital\n",
    "#  3- education\n",
    "#  4- default\n",
    "#  5- balance\n",
    "#  6- housing\n",
    "#  7- loan\n",
    "#  8- contact\n",
    "#  9- duration\n",
    "#  10- campaign\n",
    "#  11- previous\n",
    "#  12- poutcome\n",
    "#  13- deposit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['yes'],\n",
       "       ['yes'],\n",
       "       ['yes'],\n",
       "       ...,\n",
       "       ['no'],\n",
       "       ['no'],\n",
       "       ['no']], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the columns day, month and pdays do not affect the final output, thus removing those columns from x \n",
    "#while splitting data to x and y\n",
    "ct = ColumnTransformer([(\"one\",OneHotEncoder(),[1,2,3,4,6,7,8,12])],remainder =\"passthrough\")\n",
    "x = ct.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct1 = ColumnTransformer([(\"one\",OneHotEncoder(),[0])],remainder =\"passthrough\")\n",
    "y = ct1.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "       1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0,\n",
       "       0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 59, 2343, 1042, 1, 0], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test, y_train,y_test = train_test_split(x,y,test_size = 0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8929, 37)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8929, 2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\andma\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "categorical.add(Dense( units= 37, kernel_initializer= \"random_uniform\", activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical.add(Dense( units= 74, kernel_initializer= \"random_uniform\", activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical.add(Dense( units= 74, kernel_initializer= \"random_uniform\", activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical.add(Dense( units= 74, kernel_initializer= \"random_uniform\", activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical.add(Dense( units= 2, kernel_initializer= \"random_uniform\", activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical.compile(optimizer = \"rmsprop\", loss = \"categorical_crossentropy\", metrics=[\"accuracy\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/350\n",
      "8929/8929 [==============================] - 1s 62us/sample - loss: 0.1104 - acc: 0.9721\n",
      "Epoch 2/350\n",
      "8929/8929 [==============================] - 1s 68us/sample - loss: 0.0823 - acc: 0.9718\n",
      "Epoch 3/350\n",
      "8929/8929 [==============================] - 1s 61us/sample - loss: 0.1008 - acc: 0.9692\n",
      "Epoch 4/350\n",
      "8929/8929 [==============================] - 1s 62us/sample - loss: 0.0900 - acc: 0.9701\n",
      "Epoch 5/350\n",
      "8929/8929 [==============================] - 1s 63us/sample - loss: 0.0901 - acc: 0.9736\n",
      "Epoch 6/350\n",
      "8929/8929 [==============================] - 1s 63us/sample - loss: 0.0849 - acc: 0.9735\n",
      "Epoch 7/350\n",
      "8929/8929 [==============================] - 1s 61us/sample - loss: 0.0909 - acc: 0.9716\n",
      "Epoch 8/350\n",
      "8929/8929 [==============================] - 1s 62us/sample - loss: 0.0779 - acc: 0.9749\n",
      "Epoch 9/350\n",
      "8929/8929 [==============================] - ETA: 0s - loss: 0.0802 - acc: 0.974 - 1s 62us/sample - loss: 0.0820 - acc: 0.9733\n",
      "Epoch 10/350\n",
      "8929/8929 [==============================] - 1s 62us/sample - loss: 0.0803 - acc: 0.9731\n",
      "Epoch 11/350\n",
      "8929/8929 [==============================] - 1s 63us/sample - loss: 0.0930 - acc: 0.9716\n",
      "Epoch 12/350\n",
      "8929/8929 [==============================] - 1s 63us/sample - loss: 0.0909 - acc: 0.9757\n",
      "Epoch 13/350\n",
      "8929/8929 [==============================] - 1s 63us/sample - loss: 0.1063 - acc: 0.9724\n",
      "Epoch 14/350\n",
      "8929/8929 [==============================] - 1s 63us/sample - loss: 0.0841 - acc: 0.9739\n",
      "Epoch 15/350\n",
      "8929/8929 [==============================] - 1s 63us/sample - loss: 0.1023 - acc: 0.9722\n",
      "Epoch 16/350\n",
      "8929/8929 [==============================] - 1s 68us/sample - loss: 0.0908 - acc: 0.9727\n",
      "Epoch 17/350\n",
      "8929/8929 [==============================] - 1s 62us/sample - loss: 0.0982 - acc: 0.9738\n",
      "Epoch 18/350\n",
      "8929/8929 [==============================] - 1s 63us/sample - loss: 0.1007 - acc: 0.9744\n",
      "Epoch 19/350\n",
      "8929/8929 [==============================] - 1s 64us/sample - loss: 0.0975 - acc: 0.9733\n",
      "Epoch 20/350\n",
      "8929/8929 [==============================] - 1s 64us/sample - loss: 0.1005 - acc: 0.9723\n",
      "Epoch 21/350\n",
      "8929/8929 [==============================] - 1s 63us/sample - loss: 0.1092 - acc: 0.9699\n",
      "Epoch 22/350\n",
      "8929/8929 [==============================] - 1s 66us/sample - loss: 0.0840 - acc: 0.9751\n",
      "Epoch 23/350\n",
      "8929/8929 [==============================] - 1s 64us/sample - loss: 0.0810 - acc: 0.9744\n",
      "Epoch 24/350\n",
      "8929/8929 [==============================] - 1s 62us/sample - loss: 0.0934 - acc: 0.9723\n",
      "Epoch 25/350\n",
      "8929/8929 [==============================] - 1s 63us/sample - loss: 0.0921 - acc: 0.9722\n",
      "Epoch 26/350\n",
      "8929/8929 [==============================] - 1s 63us/sample - loss: 0.1152 - acc: 0.9701\n",
      "Epoch 27/350\n",
      "8929/8929 [==============================] - 1s 65us/sample - loss: 0.0906 - acc: 0.9738\n",
      "Epoch 28/350\n",
      "8929/8929 [==============================] - 1s 64us/sample - loss: 0.0998 - acc: 0.9723\n",
      "Epoch 29/350\n",
      "8929/8929 [==============================] - 1s 62us/sample - loss: 0.0976 - acc: 0.9737\n",
      "Epoch 30/350\n",
      "8929/8929 [==============================] - 1s 70us/sample - loss: 0.0856 - acc: 0.9755\n",
      "Epoch 31/350\n",
      "8929/8929 [==============================] - 1s 69us/sample - loss: 0.0937 - acc: 0.9740\n",
      "Epoch 32/350\n",
      "8929/8929 [==============================] - 1s 64us/sample - loss: 0.0952 - acc: 0.9747\n",
      "Epoch 33/350\n",
      "8929/8929 [==============================] - 1s 69us/sample - loss: 0.0789 - acc: 0.9741\n",
      "Epoch 34/350\n",
      "8929/8929 [==============================] - 1s 67us/sample - loss: 0.0929 - acc: 0.9763\n",
      "Epoch 35/350\n",
      "8929/8929 [==============================] - 1s 69us/sample - loss: 0.0642 - acc: 0.9779\n",
      "Epoch 36/350\n",
      "8929/8929 [==============================] - 1s 63us/sample - loss: 0.0774 - acc: 0.9752\n",
      "Epoch 37/350\n",
      "8929/8929 [==============================] - 1s 68us/sample - loss: 0.0989 - acc: 0.9741\n",
      "Epoch 38/350\n",
      "8929/8929 [==============================] - 1s 68us/sample - loss: 0.0986 - acc: 0.9733\n",
      "Epoch 39/350\n",
      "8929/8929 [==============================] - 1s 66us/sample - loss: 0.1134 - acc: 0.9723\n",
      "Epoch 40/350\n",
      "8929/8929 [==============================] - 1s 85us/sample - loss: 0.0663 - acc: 0.9770\n",
      "Epoch 41/350\n",
      "8929/8929 [==============================] - 1s 65us/sample - loss: 0.0919 - acc: 0.9747\n",
      "Epoch 42/350\n",
      "8929/8929 [==============================] - 1s 77us/sample - loss: 0.0979 - acc: 0.9745\n",
      "Epoch 43/350\n",
      "8929/8929 [==============================] - 1s 65us/sample - loss: 0.1015 - acc: 0.9714\n",
      "Epoch 44/350\n",
      "8929/8929 [==============================] - 1s 64us/sample - loss: 0.0918 - acc: 0.9711\n",
      "Epoch 45/350\n",
      "8929/8929 [==============================] - 1s 64us/sample - loss: 0.0954 - acc: 0.9744\n",
      "Epoch 46/350\n",
      "8929/8929 [==============================] - 1s 63us/sample - loss: 0.1036 - acc: 0.9700\n",
      "Epoch 47/350\n",
      "8929/8929 [==============================] - 1s 64us/sample - loss: 0.0754 - acc: 0.9735\n",
      "Epoch 48/350\n",
      "8929/8929 [==============================] - 1s 65us/sample - loss: 0.0884 - acc: 0.9733\n",
      "Epoch 49/350\n",
      "8929/8929 [==============================] - 1s 64us/sample - loss: 0.0861 - acc: 0.9767\n",
      "Epoch 50/350\n",
      "8929/8929 [==============================] - 1s 66us/sample - loss: 0.0854 - acc: 0.9758\n",
      "Epoch 51/350\n",
      "8929/8929 [==============================] - 1s 65us/sample - loss: 0.0850 - acc: 0.9747\n",
      "Epoch 52/350\n",
      "8929/8929 [==============================] - 1s 69us/sample - loss: 0.0865 - acc: 0.9761\n",
      "Epoch 53/350\n",
      "8929/8929 [==============================] - 1s 67us/sample - loss: 0.0705 - acc: 0.9751\n",
      "Epoch 54/350\n",
      "8929/8929 [==============================] - 1s 65us/sample - loss: 0.0860 - acc: 0.9759\n",
      "Epoch 55/350\n",
      "8929/8929 [==============================] - 1s 63us/sample - loss: 0.1069 - acc: 0.9718\n",
      "Epoch 56/350\n",
      "8929/8929 [==============================] - 1s 65us/sample - loss: 0.0930 - acc: 0.9729\n",
      "Epoch 57/350\n",
      "8929/8929 [==============================] - 1s 68us/sample - loss: 0.0821 - acc: 0.9764\n",
      "Epoch 58/350\n",
      "8929/8929 [==============================] - 1s 65us/sample - loss: 0.0922 - acc: 0.9730\n",
      "Epoch 59/350\n",
      "8929/8929 [==============================] - 1s 64us/sample - loss: 0.0782 - acc: 0.9759\n",
      "Epoch 60/350\n",
      "8929/8929 [==============================] - 1s 64us/sample - loss: 0.1136 - acc: 0.9735\n",
      "Epoch 61/350\n",
      "8929/8929 [==============================] - 1s 68us/sample - loss: 0.0906 - acc: 0.9736\n",
      "Epoch 62/350\n",
      "8929/8929 [==============================] - 1s 71us/sample - loss: 0.0862 - acc: 0.9768\n",
      "Epoch 63/350\n",
      "8929/8929 [==============================] - 1s 68us/sample - loss: 0.0928 - acc: 0.9755\n",
      "Epoch 64/350\n",
      "8929/8929 [==============================] - 1s 68us/sample - loss: 0.0838 - acc: 0.9736\n",
      "Epoch 65/350\n",
      "8929/8929 [==============================] - 1s 68us/sample - loss: 0.0832 - acc: 0.9757\n",
      "Epoch 66/350\n",
      "8929/8929 [==============================] - 1s 69us/sample - loss: 0.0816 - acc: 0.9750\n",
      "Epoch 67/350\n",
      "8929/8929 [==============================] - 1s 72us/sample - loss: 0.0949 - acc: 0.9761\n",
      "Epoch 68/350\n",
      "8929/8929 [==============================] - 1s 65us/sample - loss: 0.0800 - acc: 0.9769\n",
      "Epoch 69/350\n",
      "8929/8929 [==============================] - 1s 63us/sample - loss: 0.0917 - acc: 0.97550s - loss: 0.1031 - ac\n",
      "Epoch 70/350\n",
      "8929/8929 [==============================] - 1s 62us/sample - loss: 0.0920 - acc: 0.9773\n",
      "Epoch 71/350\n",
      "8929/8929 [==============================] - 1s 66us/sample - loss: 0.0819 - acc: 0.9747\n",
      "Epoch 72/350\n",
      "8929/8929 [==============================] - 1s 64us/sample - loss: 0.0750 - acc: 0.9751\n",
      "Epoch 73/350\n",
      "8929/8929 [==============================] - 1s 62us/sample - loss: 0.0936 - acc: 0.9770\n",
      "Epoch 74/350\n",
      "8929/8929 [==============================] - 1s 66us/sample - loss: 0.0760 - acc: 0.9772\n",
      "Epoch 75/350\n",
      "8929/8929 [==============================] - 1s 67us/sample - loss: 0.0877 - acc: 0.9757\n",
      "Epoch 76/350\n",
      "8929/8929 [==============================] - 1s 62us/sample - loss: 0.0828 - acc: 0.9764\n",
      "Epoch 77/350\n",
      "8929/8929 [==============================] - 1s 62us/sample - loss: 0.0986 - acc: 0.9765\n",
      "Epoch 78/350\n",
      "8929/8929 [==============================] - 1s 66us/sample - loss: 0.0886 - acc: 0.9773\n",
      "Epoch 79/350\n",
      "8929/8929 [==============================] - 1s 63us/sample - loss: 0.1038 - acc: 0.9757\n",
      "Epoch 80/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0930 - acc: 0.9754\n",
      "Epoch 81/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0817 - acc: 0.9751\n",
      "Epoch 82/350\n",
      "8929/8929 [==============================] - 1s 61us/sample - loss: 0.0836 - acc: 0.9777\n",
      "Epoch 83/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0800 - acc: 0.9767\n",
      "Epoch 84/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.1101 - acc: 0.9738\n",
      "Epoch 85/350\n",
      "8929/8929 [==============================] - 1s 61us/sample - loss: 0.0793 - acc: 0.9775\n",
      "Epoch 86/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0856 - acc: 0.9746\n",
      "Epoch 87/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0838 - acc: 0.9765\n",
      "Epoch 88/350\n",
      "8929/8929 [==============================] - 1s 59us/sample - loss: 0.0916 - acc: 0.9772\n",
      "Epoch 89/350\n",
      "8929/8929 [==============================] - 1s 59us/sample - loss: 0.0878 - acc: 0.9779\n",
      "Epoch 90/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0856 - acc: 0.9763\n",
      "Epoch 91/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0917 - acc: 0.9733\n",
      "Epoch 92/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0758 - acc: 0.9768\n",
      "Epoch 93/350\n",
      "8929/8929 [==============================] - 1s 62us/sample - loss: 0.0828 - acc: 0.9768\n",
      "Epoch 94/350\n",
      "8929/8929 [==============================] - 1s 61us/sample - loss: 0.0759 - acc: 0.9770\n",
      "Epoch 95/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0770 - acc: 0.9788\n",
      "Epoch 96/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0706 - acc: 0.9773\n",
      "Epoch 97/350\n",
      "8929/8929 [==============================] - 1s 61us/sample - loss: 0.0738 - acc: 0.9767\n",
      "Epoch 98/350\n",
      "8929/8929 [==============================] - 1s 61us/sample - loss: 0.1039 - acc: 0.9788\n",
      "Epoch 99/350\n",
      "8929/8929 [==============================] - 1s 63us/sample - loss: 0.0878 - acc: 0.9767\n",
      "Epoch 100/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0950 - acc: 0.9789\n",
      "Epoch 101/350\n",
      "8929/8929 [==============================] - 1s 61us/sample - loss: 0.0688 - acc: 0.9805\n",
      "Epoch 102/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0726 - acc: 0.9764\n",
      "Epoch 103/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0795 - acc: 0.9763\n",
      "Epoch 104/350\n",
      "8929/8929 [==============================] - 1s 63us/sample - loss: 0.0884 - acc: 0.9766\n",
      "Epoch 105/350\n",
      "8929/8929 [==============================] - 1s 61us/sample - loss: 0.0777 - acc: 0.9778\n",
      "Epoch 106/350\n",
      "8929/8929 [==============================] - 1s 61us/sample - loss: 0.0853 - acc: 0.9758\n",
      "Epoch 107/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0734 - acc: 0.9784\n",
      "Epoch 108/350\n",
      "8929/8929 [==============================] - 1s 61us/sample - loss: 0.0711 - acc: 0.9778\n",
      "Epoch 109/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0740 - acc: 0.9796\n",
      "Epoch 110/350\n",
      "8929/8929 [==============================] - 1s 63us/sample - loss: 0.0859 - acc: 0.9792\n",
      "Epoch 111/350\n",
      "8929/8929 [==============================] - 1s 64us/sample - loss: 0.0947 - acc: 0.9772\n",
      "Epoch 112/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0895 - acc: 0.9791\n",
      "Epoch 113/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0682 - acc: 0.9797\n",
      "Epoch 114/350\n",
      "8929/8929 [==============================] - 1s 61us/sample - loss: 0.0875 - acc: 0.9764\n",
      "Epoch 115/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0862 - acc: 0.9763\n",
      "Epoch 116/350\n",
      "8929/8929 [==============================] - 1s 62us/sample - loss: 0.0809 - acc: 0.9794\n",
      "Epoch 117/350\n",
      "8929/8929 [==============================] - 1s 64us/sample - loss: 0.0872 - acc: 0.9783\n",
      "Epoch 118/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0803 - acc: 0.9775\n",
      "Epoch 119/350\n",
      "8929/8929 [==============================] - 1s 61us/sample - loss: 0.1002 - acc: 0.9758\n",
      "Epoch 120/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0748 - acc: 0.9816\n",
      "Epoch 121/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0699 - acc: 0.9778\n",
      "Epoch 122/350\n",
      "8929/8929 [==============================] - 1s 63us/sample - loss: 0.0823 - acc: 0.9783\n",
      "Epoch 123/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0803 - acc: 0.9792\n",
      "Epoch 124/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0819 - acc: 0.9794\n",
      "Epoch 125/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0661 - acc: 0.9804\n",
      "Epoch 126/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0888 - acc: 0.9761\n",
      "Epoch 127/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0725 - acc: 0.9791\n",
      "Epoch 128/350\n",
      "8929/8929 [==============================] - 1s 61us/sample - loss: 0.0690 - acc: 0.9798\n",
      "Epoch 129/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0776 - acc: 0.9800\n",
      "Epoch 130/350\n",
      "8929/8929 [==============================] - 1s 61us/sample - loss: 0.0896 - acc: 0.9805\n",
      "Epoch 131/350\n",
      "8929/8929 [==============================] - 1s 62us/sample - loss: 0.0858 - acc: 0.9774\n",
      "Epoch 132/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0974 - acc: 0.9768\n",
      "Epoch 133/350\n",
      "8929/8929 [==============================] - 1s 62us/sample - loss: 0.0728 - acc: 0.9794\n",
      "Epoch 134/350\n",
      "8929/8929 [==============================] - 1s 73us/sample - loss: 0.0819 - acc: 0.9798\n",
      "Epoch 135/350\n",
      "8929/8929 [==============================] - 1s 72us/sample - loss: 0.0683 - acc: 0.97930s - loss: 0.0598 - a\n",
      "Epoch 136/350\n",
      "8929/8929 [==============================] - 1s 65us/sample - loss: 0.0671 - acc: 0.9787\n",
      "Epoch 137/350\n",
      "8929/8929 [==============================] - 1s 68us/sample - loss: 0.0891 - acc: 0.97950s - loss: 0.0713 - \n",
      "Epoch 138/350\n",
      "8929/8929 [==============================] - 1s 66us/sample - loss: 0.0798 - acc: 0.9794\n",
      "Epoch 139/350\n",
      "8929/8929 [==============================] - 1s 70us/sample - loss: 0.0693 - acc: 0.9775\n",
      "Epoch 140/350\n",
      "8929/8929 [==============================] - 1s 69us/sample - loss: 0.0805 - acc: 0.9798\n",
      "Epoch 141/350\n",
      "8929/8929 [==============================] - 1s 68us/sample - loss: 0.0864 - acc: 0.9792\n",
      "Epoch 142/350\n",
      "8929/8929 [==============================] - 1s 74us/sample - loss: 0.0724 - acc: 0.9798\n",
      "Epoch 143/350\n",
      "8929/8929 [==============================] - 1s 66us/sample - loss: 0.0773 - acc: 0.9788\n",
      "Epoch 144/350\n",
      "8929/8929 [==============================] - 1s 64us/sample - loss: 0.0579 - acc: 0.98080s - loss: 0.0603 - a\n",
      "Epoch 145/350\n",
      "8929/8929 [==============================] - 1s 70us/sample - loss: 0.0797 - acc: 0.9780\n",
      "Epoch 146/350\n",
      "8929/8929 [==============================] - 1s 74us/sample - loss: 0.0925 - acc: 0.9791\n",
      "Epoch 147/350\n",
      "8929/8929 [==============================] - 1s 74us/sample - loss: 0.0702 - acc: 0.9816\n",
      "Epoch 148/350\n",
      "8929/8929 [==============================] - 1s 73us/sample - loss: 0.0807 - acc: 0.9808\n",
      "Epoch 149/350\n",
      "8929/8929 [==============================] - 1s 75us/sample - loss: 0.0592 - acc: 0.9813\n",
      "Epoch 150/350\n",
      "8929/8929 [==============================] - 1s 67us/sample - loss: 0.0670 - acc: 0.9808\n",
      "Epoch 151/350\n",
      "8929/8929 [==============================] - 1s 73us/sample - loss: 0.0696 - acc: 0.9796\n",
      "Epoch 152/350\n",
      "8929/8929 [==============================] - 1s 68us/sample - loss: 0.0834 - acc: 0.9803\n",
      "Epoch 153/350\n",
      "8929/8929 [==============================] - 1s 68us/sample - loss: 0.0872 - acc: 0.9793\n",
      "Epoch 154/350\n",
      "8929/8929 [==============================] - 1s 66us/sample - loss: 0.0780 - acc: 0.9810\n",
      "Epoch 155/350\n",
      "8929/8929 [==============================] - 1s 66us/sample - loss: 0.0808 - acc: 0.9814\n",
      "Epoch 156/350\n",
      "8929/8929 [==============================] - 1s 77us/sample - loss: 0.0919 - acc: 0.9789\n",
      "Epoch 157/350\n",
      "8929/8929 [==============================] - 1s 74us/sample - loss: 0.0784 - acc: 0.9783\n",
      "Epoch 158/350\n",
      "8929/8929 [==============================] - 1s 68us/sample - loss: 0.0657 - acc: 0.9812\n",
      "Epoch 159/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8929/8929 [==============================] - 1s 66us/sample - loss: 0.0670 - acc: 0.9801\n",
      "Epoch 160/350\n",
      "8929/8929 [==============================] - 1s 61us/sample - loss: 0.0929 - acc: 0.9810\n",
      "Epoch 161/350\n",
      "8929/8929 [==============================] - 1s 62us/sample - loss: 0.0784 - acc: 0.9783\n",
      "Epoch 162/350\n",
      "8929/8929 [==============================] - 1s 65us/sample - loss: 0.0591 - acc: 0.9822\n",
      "Epoch 163/350\n",
      "8929/8929 [==============================] - 1s 61us/sample - loss: 0.0662 - acc: 0.9814\n",
      "Epoch 164/350\n",
      "8929/8929 [==============================] - 1s 61us/sample - loss: 0.0634 - acc: 0.9800\n",
      "Epoch 165/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0883 - acc: 0.9801\n",
      "Epoch 166/350\n",
      "8929/8929 [==============================] - 1s 61us/sample - loss: 0.0584 - acc: 0.9830\n",
      "Epoch 167/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0662 - acc: 0.9804\n",
      "Epoch 168/350\n",
      "8929/8929 [==============================] - 1s 61us/sample - loss: 0.0714 - acc: 0.9821\n",
      "Epoch 169/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0794 - acc: 0.9803\n",
      "Epoch 170/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0738 - acc: 0.9806\n",
      "Epoch 171/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0739 - acc: 0.9822\n",
      "Epoch 172/350\n",
      "8929/8929 [==============================] - 1s 61us/sample - loss: 0.0617 - acc: 0.9801\n",
      "Epoch 173/350\n",
      "8929/8929 [==============================] - 1s 64us/sample - loss: 0.0859 - acc: 0.9802\n",
      "Epoch 174/350\n",
      "8929/8929 [==============================] - 1s 61us/sample - loss: 0.0879 - acc: 0.9806\n",
      "Epoch 175/350\n",
      "8929/8929 [==============================] - 1s 61us/sample - loss: 0.0613 - acc: 0.9825\n",
      "Epoch 176/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0990 - acc: 0.9808\n",
      "Epoch 177/350\n",
      "8929/8929 [==============================] - 1s 61us/sample - loss: 0.0794 - acc: 0.9819\n",
      "Epoch 178/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0841 - acc: 0.9798\n",
      "Epoch 179/350\n",
      "8929/8929 [==============================] - 1s 61us/sample - loss: 0.0840 - acc: 0.9804\n",
      "Epoch 180/350\n",
      "8929/8929 [==============================] - 1s 63us/sample - loss: 0.0696 - acc: 0.9797\n",
      "Epoch 181/350\n",
      "8929/8929 [==============================] - 1s 61us/sample - loss: 0.1007 - acc: 0.9779\n",
      "Epoch 182/350\n",
      "8929/8929 [==============================] - 1s 62us/sample - loss: 0.0607 - acc: 0.9830\n",
      "Epoch 183/350\n",
      "8929/8929 [==============================] - 1s 61us/sample - loss: 0.0716 - acc: 0.9777\n",
      "Epoch 184/350\n",
      "8929/8929 [==============================] - 1s 62us/sample - loss: 0.0854 - acc: 0.9787\n",
      "Epoch 185/350\n",
      "8929/8929 [==============================] - 1s 62us/sample - loss: 0.0859 - acc: 0.9792\n",
      "Epoch 186/350\n",
      "8929/8929 [==============================] - 1s 61us/sample - loss: 0.1069 - acc: 0.9814\n",
      "Epoch 187/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0786 - acc: 0.9803\n",
      "Epoch 188/350\n",
      "8929/8929 [==============================] - 1s 63us/sample - loss: 0.0783 - acc: 0.9810\n",
      "Epoch 189/350\n",
      "8929/8929 [==============================] - 1s 61us/sample - loss: 0.0788 - acc: 0.9813\n",
      "Epoch 190/350\n",
      "8929/8929 [==============================] - 1s 62us/sample - loss: 0.1210 - acc: 0.9804\n",
      "Epoch 191/350\n",
      "8929/8929 [==============================] - 1s 61us/sample - loss: 0.0803 - acc: 0.9793\n",
      "Epoch 192/350\n",
      "8929/8929 [==============================] - 1s 64us/sample - loss: 0.0804 - acc: 0.9824\n",
      "Epoch 193/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0762 - acc: 0.9797\n",
      "Epoch 194/350\n",
      "8929/8929 [==============================] - 1s 61us/sample - loss: 0.0578 - acc: 0.9833\n",
      "Epoch 195/350\n",
      "8929/8929 [==============================] - 1s 61us/sample - loss: 0.0748 - acc: 0.9806\n",
      "Epoch 196/350\n",
      "8929/8929 [==============================] - 1s 61us/sample - loss: 0.0707 - acc: 0.9808\n",
      "Epoch 197/350\n",
      "8929/8929 [==============================] - 1s 61us/sample - loss: 0.0678 - acc: 0.9806\n",
      "Epoch 198/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0858 - acc: 0.9794\n",
      "Epoch 199/350\n",
      "8929/8929 [==============================] - 1s 63us/sample - loss: 0.0823 - acc: 0.9808\n",
      "Epoch 200/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0799 - acc: 0.9793\n",
      "Epoch 201/350\n",
      "8929/8929 [==============================] - 1s 62us/sample - loss: 0.0941 - acc: 0.9789\n",
      "Epoch 202/350\n",
      "8929/8929 [==============================] - 1s 61us/sample - loss: 0.0640 - acc: 0.9793\n",
      "Epoch 203/350\n",
      "8929/8929 [==============================] - 1s 62us/sample - loss: 0.0619 - acc: 0.9823\n",
      "Epoch 204/350\n",
      "8929/8929 [==============================] - 1s 61us/sample - loss: 0.0653 - acc: 0.9822\n",
      "Epoch 205/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0646 - acc: 0.9825\n",
      "Epoch 206/350\n",
      "8929/8929 [==============================] - 1s 61us/sample - loss: 0.0744 - acc: 0.98390s - loss: 0.0539 - ac\n",
      "Epoch 207/350\n",
      "8929/8929 [==============================] - 1s 62us/sample - loss: 0.1103 - acc: 0.9814\n",
      "Epoch 208/350\n",
      "8929/8929 [==============================] - 1s 62us/sample - loss: 0.0691 - acc: 0.9825\n",
      "Epoch 209/350\n",
      "8929/8929 [==============================] - 1s 61us/sample - loss: 0.0639 - acc: 0.9805\n",
      "Epoch 210/350\n",
      "8929/8929 [==============================] - 1s 63us/sample - loss: 0.0771 - acc: 0.9804\n",
      "Epoch 211/350\n",
      "8929/8929 [==============================] - 1s 63us/sample - loss: 0.0742 - acc: 0.9823\n",
      "Epoch 212/350\n",
      "8929/8929 [==============================] - 1s 63us/sample - loss: 0.0625 - acc: 0.9832\n",
      "Epoch 213/350\n",
      "8929/8929 [==============================] - 1s 62us/sample - loss: 0.0801 - acc: 0.9833\n",
      "Epoch 214/350\n",
      "8929/8929 [==============================] - 1s 62us/sample - loss: 0.0630 - acc: 0.9829\n",
      "Epoch 215/350\n",
      "8929/8929 [==============================] - 1s 63us/sample - loss: 0.0774 - acc: 0.9834\n",
      "Epoch 216/350\n",
      "8929/8929 [==============================] - 1s 64us/sample - loss: 0.0643 - acc: 0.9810\n",
      "Epoch 217/350\n",
      "8929/8929 [==============================] - 1s 66us/sample - loss: 0.0712 - acc: 0.9824\n",
      "Epoch 218/350\n",
      "8929/8929 [==============================] - 1s 61us/sample - loss: 0.0726 - acc: 0.9824\n",
      "Epoch 219/350\n",
      "8929/8929 [==============================] - 1s 61us/sample - loss: 0.0778 - acc: 0.9815\n",
      "Epoch 220/350\n",
      "8929/8929 [==============================] - 1s 61us/sample - loss: 0.0749 - acc: 0.9824\n",
      "Epoch 221/350\n",
      "8929/8929 [==============================] - 1s 62us/sample - loss: 0.0790 - acc: 0.9796\n",
      "Epoch 222/350\n",
      "8929/8929 [==============================] - 1s 62us/sample - loss: 0.0903 - acc: 0.9804\n",
      "Epoch 223/350\n",
      "8929/8929 [==============================] - 1s 62us/sample - loss: 0.0754 - acc: 0.9820\n",
      "Epoch 224/350\n",
      "8929/8929 [==============================] - 1s 61us/sample - loss: 0.0652 - acc: 0.9830\n",
      "Epoch 225/350\n",
      "8929/8929 [==============================] - 1s 62us/sample - loss: 0.0538 - acc: 0.9845\n",
      "Epoch 226/350\n",
      "8929/8929 [==============================] - 1s 64us/sample - loss: 0.0547 - acc: 0.9851\n",
      "Epoch 227/350\n",
      "8929/8929 [==============================] - ETA: 0s - loss: 0.0770 - acc: 0.980 - 1s 61us/sample - loss: 0.0783 - acc: 0.9807\n",
      "Epoch 228/350\n",
      "8929/8929 [==============================] - 1s 66us/sample - loss: 0.0770 - acc: 0.9828\n",
      "Epoch 229/350\n",
      "8929/8929 [==============================] - 1s 62us/sample - loss: 0.0780 - acc: 0.9835\n",
      "Epoch 230/350\n",
      "8929/8929 [==============================] - 1s 61us/sample - loss: 0.0607 - acc: 0.9841\n",
      "Epoch 231/350\n",
      "8929/8929 [==============================] - 1s 62us/sample - loss: 0.0686 - acc: 0.9839\n",
      "Epoch 232/350\n",
      "8929/8929 [==============================] - 1s 61us/sample - loss: 0.0620 - acc: 0.9845\n",
      "Epoch 233/350\n",
      "8929/8929 [==============================] - 1s 62us/sample - loss: 0.0724 - acc: 0.9814\n",
      "Epoch 234/350\n",
      "8929/8929 [==============================] - 1s 63us/sample - loss: 0.0639 - acc: 0.9824\n",
      "Epoch 235/350\n",
      "8929/8929 [==============================] - 1s 63us/sample - loss: 0.0861 - acc: 0.9814\n",
      "Epoch 236/350\n",
      "8929/8929 [==============================] - 1s 71us/sample - loss: 0.0538 - acc: 0.9851\n",
      "Epoch 237/350\n",
      "8929/8929 [==============================] - 1s 62us/sample - loss: 0.0594 - acc: 0.9835\n",
      "Epoch 238/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8929/8929 [==============================] - 1s 61us/sample - loss: 0.0995 - acc: 0.9820\n",
      "Epoch 239/350\n",
      "8929/8929 [==============================] - 1s 59us/sample - loss: 0.0631 - acc: 0.9810\n",
      "Epoch 240/350\n",
      "8929/8929 [==============================] - 1s 61us/sample - loss: 0.0661 - acc: 0.9828\n",
      "Epoch 241/350\n",
      "8929/8929 [==============================] - 1s 59us/sample - loss: 0.0672 - acc: 0.9824\n",
      "Epoch 242/350\n",
      "8929/8929 [==============================] - 1s 59us/sample - loss: 0.0796 - acc: 0.9828\n",
      "Epoch 243/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0804 - acc: 0.9816\n",
      "Epoch 244/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0741 - acc: 0.9815\n",
      "Epoch 245/350\n",
      "8929/8929 [==============================] - 1s 59us/sample - loss: 0.0764 - acc: 0.9807\n",
      "Epoch 246/350\n",
      "8929/8929 [==============================] - 1s 61us/sample - loss: 0.1073 - acc: 0.9828\n",
      "Epoch 247/350\n",
      "8929/8929 [==============================] - 1s 61us/sample - loss: 0.0811 - acc: 0.9817\n",
      "Epoch 248/350\n",
      "8929/8929 [==============================] - 1s 61us/sample - loss: 0.0548 - acc: 0.9828\n",
      "Epoch 249/350\n",
      "8929/8929 [==============================] - 1s 61us/sample - loss: 0.0728 - acc: 0.9812\n",
      "Epoch 250/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0581 - acc: 0.9831\n",
      "Epoch 251/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0559 - acc: 0.9859\n",
      "Epoch 252/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0711 - acc: 0.9821\n",
      "Epoch 253/350\n",
      "8929/8929 [==============================] - 1s 63us/sample - loss: 0.0757 - acc: 0.9845\n",
      "Epoch 254/350\n",
      "8929/8929 [==============================] - 1s 59us/sample - loss: 0.0885 - acc: 0.9813\n",
      "Epoch 255/350\n",
      "8929/8929 [==============================] - 1s 61us/sample - loss: 0.0785 - acc: 0.9823\n",
      "Epoch 256/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0575 - acc: 0.9835\n",
      "Epoch 257/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0791 - acc: 0.9814\n",
      "Epoch 258/350\n",
      "8929/8929 [==============================] - 1s 59us/sample - loss: 0.0589 - acc: 0.9816\n",
      "Epoch 259/350\n",
      "8929/8929 [==============================] - 1s 63us/sample - loss: 0.0837 - acc: 0.9835\n",
      "Epoch 260/350\n",
      "8929/8929 [==============================] - 1s 59us/sample - loss: 0.0684 - acc: 0.9847\n",
      "Epoch 261/350\n",
      "8929/8929 [==============================] - 1s 59us/sample - loss: 0.0734 - acc: 0.9839\n",
      "Epoch 262/350\n",
      "8929/8929 [==============================] - 1s 64us/sample - loss: 0.0822 - acc: 0.9821\n",
      "Epoch 263/350\n",
      "8929/8929 [==============================] - 1s 64us/sample - loss: 0.0687 - acc: 0.9834\n",
      "Epoch 264/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0791 - acc: 0.9826\n",
      "Epoch 265/350\n",
      "8929/8929 [==============================] - 1s 67us/sample - loss: 0.0586 - acc: 0.9845\n",
      "Epoch 266/350\n",
      "8929/8929 [==============================] - 1s 61us/sample - loss: 0.0646 - acc: 0.9841\n",
      "Epoch 267/350\n",
      "8929/8929 [==============================] - 1s 64us/sample - loss: 0.0912 - acc: 0.9810\n",
      "Epoch 268/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0806 - acc: 0.9832\n",
      "Epoch 269/350\n",
      "8929/8929 [==============================] - 1s 67us/sample - loss: 0.0613 - acc: 0.9820\n",
      "Epoch 270/350\n",
      "8929/8929 [==============================] - 1s 61us/sample - loss: 0.0927 - acc: 0.9821\n",
      "Epoch 271/350\n",
      "8929/8929 [==============================] - ETA: 0s - loss: 0.1017 - acc: 0.981 - 1s 61us/sample - loss: 0.1012 - acc: 0.9815\n",
      "Epoch 272/350\n",
      "8929/8929 [==============================] - 1s 59us/sample - loss: 0.1131 - acc: 0.9802\n",
      "Epoch 273/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0632 - acc: 0.9831\n",
      "Epoch 274/350\n",
      "8929/8929 [==============================] - 1s 59us/sample - loss: 0.0774 - acc: 0.9849\n",
      "Epoch 275/350\n",
      "8929/8929 [==============================] - 1s 66us/sample - loss: 0.0568 - acc: 0.9835\n",
      "Epoch 276/350\n",
      "8929/8929 [==============================] - 1s 61us/sample - loss: 0.0717 - acc: 0.9838\n",
      "Epoch 277/350\n",
      "8929/8929 [==============================] - 1s 65us/sample - loss: 0.0619 - acc: 0.9847\n",
      "Epoch 278/350\n",
      "8929/8929 [==============================] - 1s 61us/sample - loss: 0.0799 - acc: 0.9835\n",
      "Epoch 279/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0655 - acc: 0.9834\n",
      "Epoch 280/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0604 - acc: 0.9822\n",
      "Epoch 281/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0566 - acc: 0.9853\n",
      "Epoch 282/350\n",
      "8929/8929 [==============================] - 1s 61us/sample - loss: 0.0700 - acc: 0.98330s - loss: 0.0425 - acc\n",
      "Epoch 283/350\n",
      "8929/8929 [==============================] - 1s 63us/sample - loss: 0.0865 - acc: 0.9833\n",
      "Epoch 284/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0658 - acc: 0.9831\n",
      "Epoch 285/350\n",
      "8929/8929 [==============================] - 1s 63us/sample - loss: 0.0601 - acc: 0.9845\n",
      "Epoch 286/350\n",
      "8929/8929 [==============================] - 1s 61us/sample - loss: 0.0631 - acc: 0.9830\n",
      "Epoch 287/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0770 - acc: 0.9830\n",
      "Epoch 288/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0889 - acc: 0.9824\n",
      "Epoch 289/350\n",
      "8929/8929 [==============================] - 1s 59us/sample - loss: 0.0617 - acc: 0.9848\n",
      "Epoch 290/350\n",
      "8929/8929 [==============================] - 1s 62us/sample - loss: 0.0690 - acc: 0.9847\n",
      "Epoch 291/350\n",
      "8929/8929 [==============================] - 1s 61us/sample - loss: 0.0657 - acc: 0.9839\n",
      "Epoch 292/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0626 - acc: 0.9844\n",
      "Epoch 293/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0603 - acc: 0.9842\n",
      "Epoch 294/350\n",
      "8929/8929 [==============================] - 1s 61us/sample - loss: 0.0523 - acc: 0.9860\n",
      "Epoch 295/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0747 - acc: 0.9840\n",
      "Epoch 296/350\n",
      "8929/8929 [==============================] - 1s 59us/sample - loss: 0.0769 - acc: 0.9821\n",
      "Epoch 297/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0708 - acc: 0.9844\n",
      "Epoch 298/350\n",
      "8929/8929 [==============================] - 1s 61us/sample - loss: 0.0712 - acc: 0.9834\n",
      "Epoch 299/350\n",
      "8929/8929 [==============================] - 1s 61us/sample - loss: 0.0719 - acc: 0.9835\n",
      "Epoch 300/350\n",
      "8929/8929 [==============================] - 1s 59us/sample - loss: 0.0582 - acc: 0.9836\n",
      "Epoch 301/350\n",
      "8929/8929 [==============================] - 1s 61us/sample - loss: 0.1000 - acc: 0.9839\n",
      "Epoch 302/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0653 - acc: 0.9842\n",
      "Epoch 303/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0942 - acc: 0.9828\n",
      "Epoch 304/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0605 - acc: 0.98340s - loss: 0.0256 - a\n",
      "Epoch 305/350\n",
      "8929/8929 [==============================] - 1s 59us/sample - loss: 0.0971 - acc: 0.9814\n",
      "Epoch 306/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0602 - acc: 0.9860\n",
      "Epoch 307/350\n",
      "8929/8929 [==============================] - 1s 61us/sample - loss: 0.0727 - acc: 0.9839\n",
      "Epoch 308/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0725 - acc: 0.9848\n",
      "Epoch 309/350\n",
      "8929/8929 [==============================] - 1s 59us/sample - loss: 0.0885 - acc: 0.9847\n",
      "Epoch 310/350\n",
      "8929/8929 [==============================] - 1s 62us/sample - loss: 0.0655 - acc: 0.9841\n",
      "Epoch 311/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0656 - acc: 0.9858\n",
      "Epoch 312/350\n",
      "8929/8929 [==============================] - 1s 59us/sample - loss: 0.0703 - acc: 0.9829\n",
      "Epoch 313/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0605 - acc: 0.9851\n",
      "Epoch 314/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0589 - acc: 0.9840\n",
      "Epoch 315/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0642 - acc: 0.9834\n",
      "Epoch 316/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8929/8929 [==============================] - 1s 59us/sample - loss: 0.0657 - acc: 0.9836\n",
      "Epoch 317/350\n",
      "8929/8929 [==============================] - 1s 59us/sample - loss: 0.0962 - acc: 0.9793\n",
      "Epoch 318/350\n",
      "8929/8929 [==============================] - 1s 59us/sample - loss: 0.0856 - acc: 0.9839\n",
      "Epoch 319/350\n",
      "8929/8929 [==============================] - 1s 59us/sample - loss: 0.0743 - acc: 0.9825\n",
      "Epoch 320/350\n",
      "8929/8929 [==============================] - 1s 61us/sample - loss: 0.0646 - acc: 0.9844\n",
      "Epoch 321/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0655 - acc: 0.9835\n",
      "Epoch 322/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0580 - acc: 0.9845\n",
      "Epoch 323/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0716 - acc: 0.9822\n",
      "Epoch 324/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0587 - acc: 0.9847\n",
      "Epoch 325/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0613 - acc: 0.9836\n",
      "Epoch 326/350\n",
      "8929/8929 [==============================] - 1s 61us/sample - loss: 0.0543 - acc: 0.9860\n",
      "Epoch 327/350\n",
      "8929/8929 [==============================] - 1s 61us/sample - loss: 0.0554 - acc: 0.9859\n",
      "Epoch 328/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0613 - acc: 0.9857\n",
      "Epoch 329/350\n",
      "8929/8929 [==============================] - 1s 59us/sample - loss: 0.0725 - acc: 0.9824\n",
      "Epoch 330/350\n",
      "8929/8929 [==============================] - 1s 59us/sample - loss: 0.0703 - acc: 0.9823\n",
      "Epoch 331/350\n",
      "8929/8929 [==============================] - 1s 62us/sample - loss: 0.0619 - acc: 0.9830\n",
      "Epoch 332/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0588 - acc: 0.9847\n",
      "Epoch 333/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0675 - acc: 0.9839\n",
      "Epoch 334/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0707 - acc: 0.9833\n",
      "Epoch 335/350\n",
      "8929/8929 [==============================] - 1s 59us/sample - loss: 0.0700 - acc: 0.9850\n",
      "Epoch 336/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0569 - acc: 0.9840\n",
      "Epoch 337/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0618 - acc: 0.9854\n",
      "Epoch 338/350\n",
      "8929/8929 [==============================] - 1s 61us/sample - loss: 0.0862 - acc: 0.9839\n",
      "Epoch 339/350\n",
      "8929/8929 [==============================] - 1s 62us/sample - loss: 0.0590 - acc: 0.9848\n",
      "Epoch 340/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0669 - acc: 0.9841\n",
      "Epoch 341/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0560 - acc: 0.9848\n",
      "Epoch 342/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0927 - acc: 0.9838\n",
      "Epoch 343/350\n",
      "8929/8929 [==============================] - 1s 59us/sample - loss: 0.0738 - acc: 0.9833\n",
      "Epoch 344/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0543 - acc: 0.9848\n",
      "Epoch 345/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0808 - acc: 0.9858\n",
      "Epoch 346/350\n",
      "8929/8929 [==============================] - 1s 59us/sample - loss: 0.0474 - acc: 0.9867\n",
      "Epoch 347/350\n",
      "8929/8929 [==============================] - 1s 59us/sample - loss: 0.0565 - acc: 0.9844\n",
      "Epoch 348/350\n",
      "8929/8929 [==============================] - 1s 59us/sample - loss: 0.0807 - acc: 0.9834\n",
      "Epoch 349/350\n",
      "8929/8929 [==============================] - 1s 59us/sample - loss: 0.0702 - acc: 0.9856\n",
      "Epoch 350/350\n",
      "8929/8929 [==============================] - 1s 60us/sample - loss: 0.0708 - acc: 0.9836\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x290d11536d8>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical.fit(x_train, y_train, epochs = 350) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = categorical.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0000000e+00, 0.0000000e+00],\n",
       "       [4.2341362e-09, 1.0000000e+00],\n",
       "       [1.0000000e+00, 0.0000000e+00],\n",
       "       ...,\n",
       "       [8.8607122e-19, 1.0000000e+00],\n",
       "       [1.0000000e+00, 0.0000000e+00],\n",
       "       [1.1459228e-02, 9.8854083e-01]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = ypred>0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deposit = [\"No\",\"Yes\"]\n",
    "yp = categorical.predict(sc.transform(ct.transform([[59, 'admin.', 'married', 'secondary', 'no', 2343, 'yes', 'no',\n",
    "       'unknown', 1042, 1, 0, 'unknown']])))\n",
    "prediction = deposit[np.argmax(yp)]\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>deposit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>2343</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>1042</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     job  marital  education default  balance housing loan  contact  \\\n",
       "0   59  admin.  married  secondary      no     2343     yes   no  unknown   \n",
       "\n",
       "   day month  duration  campaign  pdays  previous poutcome deposit  \n",
       "0    5   may      1042         1     -1         0  unknown     yes  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
